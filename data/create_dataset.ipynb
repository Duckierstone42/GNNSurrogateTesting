{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found target hash in reduced_evolutions/two_stage_surr_evolution_v2/generation_1/c0f1f7885c\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"reduced_evolutions/two_stage_surr_evolution_v2\"\n",
    "target_hash = \"c0f1f7885c\"\n",
    "for generation_num in range(1, 16):\n",
    "    generation_dir = os.path.join(base_dir, f'generation_{generation_num}')\n",
    "\n",
    "    for individual_hash in os.listdir(generation_dir):\n",
    "        individual_dir = os.path.join(generation_dir, individual_hash)\n",
    "\n",
    "        if target_hash == individual_hash:\n",
    "            print(f\"Found target hash in {individual_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid includes best epochs of running individual\n",
    "\n",
    "compiled_data_gen_1_2 = []\n",
    "compiled_data_gen_3_above = []\n",
    "\n",
    "base_dir = \"reduced_evolutions/two_stage_surr_evolution_v2\"\n",
    "\n",
    "for generation_num in range(1, 16):\n",
    "    print(f\"Processing generation {generation_num}\")\n",
    "    generation_dir = os.path.join(base_dir, f'generation_{generation_num}')\n",
    "    \n",
    "    if not os.path.isdir(generation_dir):\n",
    "        print(f\"Generation {generation_num} not found\")\n",
    "        continue\n",
    "    \n",
    "    for individual_hash in os.listdir(generation_dir):\n",
    "        individual_dir = os.path.join(generation_dir, individual_hash)\n",
    "        \n",
    "        metric_file = os.path.join(individual_dir, 'metrics.csv')\n",
    "        if not os.path.isfile(metric_file):\n",
    "            print(f\"Metric file not found at {metric_file}\")\n",
    "            continue\n",
    "\n",
    "        out_file = os.path.join(base_dir, 'out.csv')\n",
    "        if not os.path.isfile(out_file):\n",
    "            print(f\"out.csv not found at {out_file}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            metrics_df = pd.read_csv(metric_file)\n",
    "            if 'epoch_num' not in metrics_df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Select the best epoch (minimum val_epoch_loss)\n",
    "            best_epoch_row = metrics_df.loc[metrics_df['val_epoch_loss'].idxmin()]\n",
    "            \n",
    "            out_df = pd.read_csv(out_file)\n",
    "            if 'genome' not in out_df.columns:\n",
    "                print(f\"Genome column not found in {out_file}\")\n",
    "                continue\n",
    "            \n",
    "            genome_value = out_df[out_df['hash'] == individual_hash]['genome'].iloc[0]\n",
    "            \n",
    "            best_epoch_row['generation'] = generation_num\n",
    "            best_epoch_row['individual_hash'] = individual_hash\n",
    "            best_epoch_row['genome'] = genome_value\n",
    "            \n",
    "            if generation_num in [1, 2]:\n",
    "                compiled_data_gen_1_2.append(best_epoch_row)\n",
    "            else:\n",
    "                compiled_data_gen_3_above.append(best_epoch_row)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric_file} or {out_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "compiled_df_gen_1_2 = pd.DataFrame(compiled_data_gen_1_2)\n",
    "compiled_df_gen_3_above = pd.DataFrame(compiled_data_gen_3_above)\n",
    "\n",
    "compiled_df_gen_1_2.to_csv(\"valid_data_train.csv\", index=False)\n",
    "compiled_df_gen_3_above.to_csv(\"valid_data_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invalid includes best epochs of each individual\n",
    "compiled_data_gen_1_2 = []\n",
    "compiled_data_gen_3_above = []\n",
    "\n",
    "base_dir = \"reduced_evolutions/two_stage_surr_evolution_v2\"\n",
    "\n",
    "for generation_num in range(1, 16):\n",
    "    print(f\"Processing generation {generation_num}\")\n",
    "    generation_dir = os.path.join(base_dir, f'generation_{generation_num}')\n",
    "    \n",
    "    if not os.path.isdir(generation_dir):\n",
    "        print(f\"Generation {generation_num} not found\")\n",
    "        continue\n",
    "    \n",
    "    for individual_hash in os.listdir(generation_dir):\n",
    "        individual_dir = os.path.join(generation_dir, individual_hash)\n",
    "        \n",
    "        metric_file = os.path.join(individual_dir, 'metrics.csv')\n",
    "        if not os.path.isfile(metric_file):\n",
    "            print(f\"Metric file not found at {metric_file}\")\n",
    "            continue\n",
    "\n",
    "        out_file = os.path.join(base_dir, 'out.csv')\n",
    "        if not os.path.isfile(out_file):\n",
    "            print(f\"out.csv not found at {out_file}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            metrics_df = pd.read_csv(metric_file)\n",
    "            \n",
    "            if 'epoch_num' not in metrics_df.columns:\n",
    "                dummy_row = {\n",
    "                    'train_epoch_loss': 300,\n",
    "                    'uw_val_epoch_loss': 300,\n",
    "                    'val_epoch_loss': 300,\n",
    "                    'iou_loss': 300,\n",
    "                    'giou_loss': 300,\n",
    "                    'diou_loss': 300,\n",
    "                    'ciou_loss': 300,\n",
    "                    'center_loss': 300,\n",
    "                    'size_loss': 300,\n",
    "                    'obj_loss': 300,\n",
    "                    'precision': -300,\n",
    "                    'recall': -300,\n",
    "                    'f1_score': -300,\n",
    "                    'average_precision': -300,\n",
    "                    'true_positives': -300,\n",
    "                    'false_positives': -300,\n",
    "                    'false_negatives': -300,\n",
    "                    'epoch_num': 0\n",
    "                }\n",
    "                metrics_df = pd.DataFrame([dummy_row])\n",
    "            \n",
    "            best_epoch_row = metrics_df.loc[metrics_df['val_epoch_loss'].idxmin()]\n",
    "            \n",
    "            out_df = pd.read_csv(out_file)\n",
    "            if 'genome' not in out_df.columns:\n",
    "                print(f\"Genome column not found in {out_file}\")\n",
    "                continue\n",
    "            \n",
    "            genome_value = out_df[out_df['hash'] == individual_hash]['genome'].iloc[0]\n",
    "            \n",
    "            best_epoch_row['generation'] = generation_num\n",
    "            best_epoch_row['individual_hash'] = individual_hash\n",
    "            best_epoch_row['genome'] = genome_value\n",
    "            \n",
    "            if generation_num in [1, 2]:\n",
    "                compiled_data_gen_1_2.append(best_epoch_row)\n",
    "            else:\n",
    "                compiled_data_gen_3_above.append(best_epoch_row)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric_file} or {out_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "compiled_df_gen_1_2 = pd.DataFrame(compiled_data_gen_1_2)\n",
    "compiled_df_gen_3_above = pd.DataFrame(compiled_data_gen_3_above)\n",
    "\n",
    "compiled_df_gen_1_2.to_csv(\"invalid_data_train.csv\", index=False)\n",
    "compiled_df_gen_3_above.to_csv(\"invalid_data_valid.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile has every genome and every epoch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "compiled_data = []\n",
    "\n",
    "base_dir = \"reduced_evolutions/two_stage_surr_evolution_v2\"\n",
    "\n",
    "for generation_num in range(1, 16):\n",
    "    print(f\"Processing generation {generation_num}\")\n",
    "    generation_dir = os.path.join(base_dir, f'generation_{generation_num}')\n",
    "\n",
    "    if not os.path.isdir(generation_dir):\n",
    "        print(f\"Generation {generation_num} not found\")\n",
    "        continue\n",
    "\n",
    "    for individual_hash in os.listdir(generation_dir):\n",
    "        individual_dir = os.path.join(generation_dir, individual_hash)\n",
    "\n",
    "        metric_file = os.path.join(individual_dir, 'metrics.csv')\n",
    "        if not os.path.isfile(metric_file):\n",
    "            print(f\"Metric file not found at {metric_file}\")\n",
    "            continue\n",
    "\n",
    "        out_file = os.path.join(base_dir, 'out.csv')\n",
    "        if not os.path.isfile(out_file):\n",
    "            print(f\"out.csv not found at {out_file}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            metrics_df = pd.read_csv(metric_file)\n",
    "\n",
    "            if 'epoch_num' not in metrics_df.columns:\n",
    "                dummy_row = {\n",
    "                    'train_epoch_loss': 300,\n",
    "                    'uw_val_epoch_loss': 300,\n",
    "                    'val_epoch_loss': 300,\n",
    "                    'iou_loss': 300,\n",
    "                    'giou_loss': 300,\n",
    "                    'diou_loss': 300,\n",
    "                    'ciou_loss': 300,\n",
    "                    'center_loss': 300,\n",
    "                    'size_loss': 300,\n",
    "                    'obj_loss': 300,\n",
    "                    'precision': -300,\n",
    "                    'recall': -300,\n",
    "                    'f1_score': -300,\n",
    "                    'average_precision': -300,\n",
    "                    'true_positives': -300,\n",
    "                    'false_positives': -300,\n",
    "                    'false_negatives': -300,\n",
    "                    'epoch_num': 0\n",
    "                }\n",
    "                metrics_df = pd.DataFrame([dummy_row])\n",
    "\n",
    "            out_df = pd.read_csv(out_file)\n",
    "            if 'genome' not in out_df.columns:\n",
    "                print(f\"Genome column not found in {out_file}\")\n",
    "                continue\n",
    "\n",
    "            genome_value = out_df[out_df['hash'] == individual_hash]['genome'].iloc[0]\n",
    "            # Add generation, individual hash, and genome to all rows\n",
    "            metrics_df['generation'] = generation_num\n",
    "            metrics_df['individual_hash'] = individual_hash\n",
    "            metrics_df['genome'] = genome_value\n",
    "\n",
    "            # Append all rows from metrics_df to compiled_data\n",
    "            compiled_data.extend(metrics_df.to_dict('records'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric_file} or {out_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "compiled_df = pd.DataFrame(compiled_data)\n",
    "compiled_df.to_csv(\"compiled_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiled_data_best_epoch includes best epoch of each individual\n",
    "\n",
    "compiled_data_best_epoch = []\n",
    "\n",
    "base_dir = \"reduced_evolutions/two_stage_surr_evolution_v2\"\n",
    "\n",
    "for generation_num in range(1, 16):\n",
    "    print(f\"Processing generation {generation_num}\")\n",
    "    generation_dir = os.path.join(base_dir, f'generation_{generation_num}')\n",
    "    \n",
    "    if not os.path.isdir(generation_dir):\n",
    "        print(f\"Generation {generation_num} not found\")\n",
    "        continue\n",
    "    \n",
    "    for individual_hash in os.listdir(generation_dir):\n",
    "        individual_dir = os.path.join(generation_dir, individual_hash)\n",
    "        \n",
    "        metric_file = os.path.join(individual_dir, 'metrics.csv')\n",
    "        if not os.path.isfile(metric_file):\n",
    "            print(f\"Metric file not found at {metric_file}\")\n",
    "            continue\n",
    "\n",
    "        out_file = os.path.join(base_dir, 'out.csv')\n",
    "        if not os.path.isfile(out_file):\n",
    "            print(f\"out.csv not found at {out_file}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            metrics_df = pd.read_csv(metric_file)\n",
    "            if 'epoch_num' not in metrics_df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Select the best epoch (minimum val_epoch_loss)\n",
    "            best_epoch_row = metrics_df.loc[metrics_df['val_epoch_loss'].idxmin()]\n",
    "            \n",
    "            out_df = pd.read_csv(out_file)\n",
    "            if 'genome' not in out_df.columns:\n",
    "                print(f\"Genome column not found in {out_file}\")\n",
    "                continue\n",
    "            \n",
    "            genome_value = out_df[out_df['hash'] == individual_hash]['genome'].iloc[0]\n",
    "            \n",
    "            best_epoch_row['generation'] = generation_num\n",
    "            best_epoch_row['individual_hash'] = individual_hash\n",
    "            best_epoch_row['genome'] = genome_value\n",
    "            \n",
    "            compiled_data_best_epoch.append(best_epoch_row)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {metric_file} or {out_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "compiled_df_best_epoch = pd.DataFrame(compiled_data_best_epoch)\n",
    "\n",
    "compiled_df_best_epoch.to_csv(\"compiled_data_best_epoch.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_nas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
